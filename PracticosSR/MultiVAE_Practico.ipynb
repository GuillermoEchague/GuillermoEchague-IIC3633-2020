{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "MultiVAE_Practico.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ahq3V1FYhx"
      },
      "source": [
        "# Variational autoencoders for collaborative filtering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpghG7ADFYhy"
      },
      "source": [
        "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
        "\n",
        "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOzM2Du1O1ot",
        "outputId": "bef6af2e-dbcd-4fa2-94a5-f07ff5bfba61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/6d/2348df00a34baaabdef0fdb4f46f962f7a8a6720362c26c3a44a249767ea/tensorflow_gpu-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (2.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.35.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.16.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.7.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 53.4MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.1.7)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.0.post1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.8.0)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow-gpu==1.14) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (44.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.1)\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9EU9SzAI1Vs",
        "outputId": "a697c6f5-f373-4749-c79d-db90e7d07c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "!pip install Bottleneck"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Bottleneck\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/08/278c6ee569458e168096f6b51019cc1c81c288da3d1026a22ee2ccead102/Bottleneck-1.3.2.tar.gz (88kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 81kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.0MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from Bottleneck) (1.16.4)\n",
            "Building wheels for collected packages: Bottleneck\n",
            "  Building wheel for Bottleneck (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Bottleneck: filename=Bottleneck-1.3.2-cp27-cp27mu-linux_x86_64.whl size=315101 sha256=151aa531f82d4a9431b252c20a08ce3d1a1d464c6fed233eb4c2f410ccb52d46\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/a9/12/41b13e8b44889ab05ec4dcc91f27da21634bacf2a0e87473b8\n",
            "Successfully built Bottleneck\n",
            "Installing collected packages: Bottleneck\n",
            "Successfully installed Bottleneck-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK_96uetFYhz"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
        "\n",
        "import bottleneck as bn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8jolZYFYh4"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5WFiDZRFYh5"
      },
      "source": [
        "We load the data and create train/validation/test splits following strong generalization: \n",
        "\n",
        "- We split all users into training/validation/test sets. \n",
        "\n",
        "- We train models using the entire click history of the training users. \n",
        "\n",
        "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmGA2EPQFYh6"
      },
      "source": [
        "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA4ezX8MJUA1",
        "outputId": "b64f6e99-6b40-43d0-acfe-1d8cd7f71166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
        "!unzip /content/ml-20m.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-19 19:06:48--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 198702078 (189M) [application/zip]\n",
            "Saving to: ‘ml-20m.zip’\n",
            "\n",
            "ml-20m.zip          100%[===================>] 189.50M  57.6MB/s    in 3.6s    \n",
            "\n",
            "2020-10-19 19:06:52 (53.0 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n",
            "\n",
            "Archive:  /content/ml-20m.zip\n",
            "   creating: ml-20m/\n",
            "  inflating: ml-20m/genome-scores.csv  \n",
            "  inflating: ml-20m/genome-tags.csv  \n",
            "  inflating: ml-20m/links.csv        \n",
            "  inflating: ml-20m/movies.csv       \n",
            "  inflating: ml-20m/ratings.csv      \n",
            "  inflating: ml-20m/README.txt       \n",
            "  inflating: ml-20m/tags.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-80sYNYFYh7"
      },
      "source": [
        "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
        "DATA_DIR = '/content/ml-20m'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnwdl8CbFYiA"
      },
      "source": [
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), header=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn_jtYGHFYiE"
      },
      "source": [
        "# binarize the data (only keep ratings >= 4)\n",
        "raw_data = raw_data[raw_data['rating'] > 3.5]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehnKTGiFYiJ",
        "outputId": "5812a130-1544-42f4-8b73-fc76a37c898d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userId  movieId  rating   timestamp\n",
              "6        1      151     4.0  1094785734\n",
              "7        1      223     4.0  1112485573\n",
              "8        1      253     4.0  1112484940\n",
              "9        1      260     4.0  1112484826\n",
              "10       1      293     4.0  1112484703"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1094785734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>223</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112485573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>253</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>260</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzYgRQIiFYiO"
      },
      "source": [
        "### Data splitting procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qVs5EEqFYiP"
      },
      "source": [
        "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
        "- Use all the items from the training users as item set\n",
        "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDPvNl-QFYiQ"
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "    return count"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKYy5rGjFYiU"
      },
      "source": [
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
        "    \n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    return tp, usercount, itemcount"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWYHa34vFYiX"
      },
      "source": [
        "Only keep items that are clicked on by at least 5 users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8ytmY4lFYiX"
      },
      "source": [
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay8PGVQDFYia",
        "outputId": "e81ed1d0-c40f-4a87-9f77-2a5d0a3b8004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After filtering, there are 9990682 watching events from 136677 users and 20720 movies (sparsity: 0.353%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vientq_DFYic"
      },
      "source": [
        "unique_uid = user_activity.index\n",
        "\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDe3B_KYFYif"
      },
      "source": [
        "# create train/validation/test users\n",
        "n_users = unique_uid.size\n",
        "n_heldout_users = 10000\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "te_users = unique_uid[(n_users - n_heldout_users):]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60FBs88zFYih"
      },
      "source": [
        "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxCxoAh1FYik"
      },
      "source": [
        "unique_sid = pd.unique(train_plays['movieId'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCcfXDUvFYin"
      },
      "source": [
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKgIGJy1FYiq"
      },
      "source": [
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fG-zwHSFYis"
      },
      "source": [
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1k2d_g2FYiu"
      },
      "source": [
        "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJU3Ncf7FYiw",
        "outputId": "ae72c311-59d7-4a9f-c4f2-6bbc0e9a0495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptvFIhlsFYiy"
      },
      "source": [
        "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX261EFPFYi1",
        "outputId": "0d22573c-80bf-4e97-b208-8ee4f5f4b8ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfPenbm2FYi3"
      },
      "source": [
        "### Save the data into (user_index, item_index) format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfJU_gBkFYi3"
      },
      "source": [
        "def numerize(tp):\n",
        "    uid = map(lambda x: profile2id[x], tp['userId'])\n",
        "    sid = map(lambda x: show2id[x], tp['movieId'])\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUTKUFEAFYi6"
      },
      "source": [
        "train_data = numerize(train_plays)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ArJf0e8FYi8"
      },
      "source": [
        "vad_data_tr = numerize(vad_plays_tr)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugbb4-ThFYi_"
      },
      "source": [
        "vad_data_te = numerize(vad_plays_te)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_17Rkt3jFYjB"
      },
      "source": [
        "test_data_tr = numerize(test_plays_tr)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iG-vxzWFYjD"
      },
      "source": [
        "test_data_te = numerize(test_plays_te)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBJhcqMbFYjF"
      },
      "source": [
        "## Model definition and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlEMlH6TFYjF"
      },
      "source": [
        "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNtUyqeFYjF"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcrNQ2mYFYjG"
      },
      "source": [
        "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI37y0ciFYjG"
      },
      "source": [
        "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
        "\n",
        "$$\n",
        "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
        "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCD6bKYFYjH"
      },
      "source": [
        "The objective for Multi-DAE for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
        "$$\n",
        "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNHkjNS_FYjH"
      },
      "source": [
        "class MultiDAE(object):\n",
        "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims is None:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "        else:\n",
        "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        \n",
        "        self.lam = lam\n",
        "        self.lr = lr\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.construct_placeholders()\n",
        "\n",
        "    def construct_placeholders(self):        \n",
        "        self.input_ph = tf.placeholder(\n",
        "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
        "\n",
        "    def build_graph(self):\n",
        "\n",
        "        self.construct_weights()\n",
        "\n",
        "        saver, logits = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        # per-user average negative log-likelihood\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph, axis=1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        loss = neg_ll + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('loss', loss)\n",
        "        merged = tf.summary.merge_all()\n",
        "        return saver, logits, loss, train_op, merged\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # construct forward graph        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return tf.train.Saver(), h\n",
        "\n",
        "    def construct_weights(self):\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        # define weights\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
        "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_{}\".format(i+1)\n",
        "            \n",
        "            self.weights.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases[-1])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYKe5hIIFYjK"
      },
      "source": [
        "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
        "$$\n",
        "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxGbnGCNFYjK"
      },
      "source": [
        "class MultiVAE(MultiDAE):\n",
        "\n",
        "    def construct_placeholders(self):\n",
        "        super(MultiVAE, self).construct_placeholders()\n",
        "\n",
        "        # placeholders with default values when scoring\n",
        "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
        "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
        "        \n",
        "    def build_graph(self):\n",
        "        self._construct_weights()\n",
        "\n",
        "        saver, logits, KL = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph,\n",
        "            axis=-1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        \n",
        "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('KL', KL)\n",
        "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
        "        merged = tf.summary.merge_all()\n",
        "\n",
        "        return saver, logits, neg_ELBO, train_op, merged\n",
        "    \n",
        "    def q_graph(self):\n",
        "        mu_q, std_q, KL = None, None, None\n",
        "        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_q) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "            else:\n",
        "                mu_q = h[:, :self.q_dims[-1]]\n",
        "                logvar_q = h[:, self.q_dims[-1]:]\n",
        "\n",
        "                std_q = tf.exp(0.5 * logvar_q)\n",
        "                KL = tf.reduce_mean(tf.reduce_sum(\n",
        "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
        "        return mu_q, std_q, KL\n",
        "\n",
        "    def p_graph(self, z):\n",
        "        h = z\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_p) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # q-network\n",
        "        mu_q, std_q, KL = self.q_graph()\n",
        "        epsilon = tf.random_normal(tf.shape(std_q))\n",
        "\n",
        "        sampled_z = mu_q + self.is_training_ph *\\\n",
        "            epsilon * std_q\n",
        "\n",
        "        # p-network\n",
        "        logits = self.p_graph(sampled_z)\n",
        "        \n",
        "        return tf.train.Saver(), logits, KL\n",
        "\n",
        "    def _construct_weights(self):\n",
        "        self.weights_q, self.biases_q = [], []\n",
        "        \n",
        "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
        "            if i == len(self.q_dims[:-1]) - 1:\n",
        "                # we need two sets of parameters for mean and variance,\n",
        "                # respectively\n",
        "                d_out *= 2\n",
        "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_q_{}\".format(i+1)\n",
        "            \n",
        "            self.weights_q.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_q.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
        "            \n",
        "        self.weights_p, self.biases_p = [], []\n",
        "\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
        "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_p_{}\".format(i+1)\n",
        "            self.weights_p.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_p.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_p[-1])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODsCIU-fFYjM"
      },
      "source": [
        "### Training/validation data, hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGSGE8zeFYjM"
      },
      "source": [
        "Load the pre-processed training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEfmgezwFYjM"
      },
      "source": [
        "unique_sid = list()\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "    for line in f:\n",
        "        unique_sid.append(line.strip())\n",
        "\n",
        "n_items = len(unique_sid)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhV3WVq4FYjO"
      },
      "source": [
        "def load_train_data(csv_file):\n",
        "    tp = pd.read_csv(csv_file)\n",
        "    n_users = tp['uid'].max() + 1\n",
        "\n",
        "    rows, cols = tp['uid'], tp['sid']\n",
        "    data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                             (rows, cols)), dtype='float64',\n",
        "                             shape=(n_users, n_items))\n",
        "    return data"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmA2gNL3FYjQ"
      },
      "source": [
        "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1AhXPsNFYjR"
      },
      "source": [
        "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
        "    tp_tr = pd.read_csv(csv_file_tr)\n",
        "    tp_te = pd.read_csv(csv_file_te)\n",
        "\n",
        "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    return data_tr, data_te"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di1oeGm2FYjT"
      },
      "source": [
        "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
        "                                           os.path.join(pro_dir, 'validation_te.csv'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk8iKyDzFYjV"
      },
      "source": [
        "Set up training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETG2JNpGFYjW"
      },
      "source": [
        "N = train_data.shape[0]\n",
        "idxlist = range(N)\n",
        "\n",
        "# training batch size\n",
        "batch_size = 1000\n",
        "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
        "\n",
        "N_vad = vad_data_tr.shape[0]\n",
        "idxlist_vad = range(N_vad)\n",
        "\n",
        "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
        "batch_size_vad = 2000\n",
        "\n",
        "# the total number of gradient updates for annealing\n",
        "total_anneal_steps = 200000\n",
        "# largest annealing parameter\n",
        "anneal_cap = 0.2"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9hAllGaFYjZ"
      },
      "source": [
        "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsRjxtjSFYjZ"
      },
      "source": [
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    normalized discounted cumulative gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "    # topk predicted score\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "    # build the discount template\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQz5SmxzFYjb"
      },
      "source": [
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3eDxiwkFYjd"
      },
      "source": [
        "### Train a Multi-VAE^{PR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XTyfWXXFYje"
      },
      "source": [
        "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxge_UC5FYje"
      },
      "source": [
        "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVZTnXauFYje"
      },
      "source": [
        "p_dims = [200, 600, n_items]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUwFoLhRFYjh",
        "outputId": "0aee1312-e3e2-427f-c4db-0ec242e8a3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1019 19:08:13.834397 140136353933184 deprecation.py:506] From <ipython-input-31-318b0755b4c1>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W1019 19:08:14.019330 140136353933184 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1205: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yd73_vSFYjj"
      },
      "source": [
        "Set up logging and checkpoint directory\n",
        "\n",
        "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
        "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDzGG4VnFYjj"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HRfL9eXFYjl",
        "outputId": "adffef98-2119-457b-ec52-a9218715a725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "log_dir = '/content/log/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /content/log/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onllv_KFFYjn",
        "outputId": "f8aa646a-beaa-44db-fb3b-2a42f9be143b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEUws3MBFYjo"
      },
      "source": [
        "n_epochs = 20"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xjH1qvYQ1t_"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ceanmc5-FYjr",
        "outputId": "50c6c8d6-18f5-44e6-d0f6-933435f8ceb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "\n",
        "    update_count = 0.0\n",
        "    \n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            if total_anneal_steps > 0:\n",
        "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "            else:\n",
        "                anneal = anneal_cap\n",
        "            \n",
        "            feed_dict = {vae.input_ph: X, \n",
        "                         vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, \n",
        "                                           global_step=epoch * batches_per_epoch + bnum) \n",
        "            \n",
        "            update_count += 1\n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [06:56<00:00, 20.67s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LemP9VhNFYjt",
        "outputId": "79654a11-91b1-4fd0-c9f0-095e6950d10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeMzPudfFYju"
      },
      "source": [
        "### Load the test data and compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsRAPEkFFYju"
      },
      "source": [
        "test_data_tr, test_data_te = load_tr_te_data(\n",
        "    os.path.join(pro_dir, 'test_tr.csv'),\n",
        "    os.path.join(pro_dir, 'test_te.csv'))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldrY0hJhFYjx"
      },
      "source": [
        "N_test = test_data_tr.shape[0]\n",
        "idxlist_test = range(N_test)\n",
        "\n",
        "batch_size_test = 2000"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKENimMVFYjz"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0)\n",
        "saver, logits_var, _, _, _ = vae.build_graph()    "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZsTJ6wPFYj0"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkeAm-doFYj1",
        "outputId": "333cc7c7-9f90-43ed-bd6e-0bdf5a640ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBd_FOB3FYj5",
        "outputId": "f324a4bf-e0c6-4e3e-82a3-bb96fec22b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "\n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "    \n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1019 19:15:14.070822 140136353933184 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5jiCJtjFYj6",
        "outputId": "cd2608ab-32db-4d0c-ab6c-da62a60a1065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.40980 (0.00209)\n",
            "Test Recall@20=0.38114 (0.00269)\n",
            "Test Recall@50=0.52217 (0.00288)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_UQqKHTbW2Y"
      },
      "source": [
        "## Activity\n",
        "Train and test multi-DAE model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt6c7n3vFYj8"
      },
      "source": [
        "### Train a Multi-DAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sxbccfxFYj8"
      },
      "source": [
        "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtERLP50FYj8"
      },
      "source": [
        "p_dims = [200, n_items]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj2JohEIFYj-"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oTDQAmdFYkA"
      },
      "source": [
        "Set up logging and checkpoint directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-47-HpT4FYkA"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ss1ShooFYkD",
        "outputId": "d1b4db92-1475-4e5a-b195-ad316a5d5322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "log_dir = '/volmount/log/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /volmount/log/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHnoMeb2FYkF",
        "outputId": "cd48fd23-8eab-4d0e-f8d6-074ef9a5c47a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXTkHeCwFYkH"
      },
      "source": [
        "n_epochs = 200"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUWc5lnHFYkI"
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            feed_dict = {dae.input_ph: X, \n",
        "                         dae.keep_prob_ph: 0.5}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
        "                    \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8sTDoZEFYkK",
        "outputId": "abd875fc-261e-478f-9926-f92d4701fb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtAk0mYFYkM"
      },
      "source": [
        "### Compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ8KXJslFYkN"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
        "saver, logits_var, _, _, _ = dae.build_graph()    "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_wplMBeFYkO"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLyop0oFYkO",
        "outputId": "10b771ba-f170-40da-bc6d-a41f0ecf4471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jONQoamqFYkQ"
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:    \n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "    \n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "\n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jUmIokmFYkR",
        "outputId": "0198b54b-cf4b-4dd4-b5d5-42d87012543a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.41988 (0.00213)\n",
            "Test Recall@20=0.38819 (0.00269)\n",
            "Test Recall@50=0.52276 (0.00284)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}